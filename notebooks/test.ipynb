{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full runnable code for the StoryFlowAgent example\n",
    "from typing import AsyncGenerator\n",
    "from typing_extensions import override\n",
    "\n",
    "from loguru import logger\n",
    "from pydantic import BaseModel, Field\n",
    "from google.adk.agents import LlmAgent, BaseAgent, LoopAgent, SequentialAgent\n",
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "from google.genai import types\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.events import Event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constants ---\n",
    "APP_NAME = \"story_app\"\n",
    "USER_ID = \"12345\"\n",
    "SESSION_ID = \"123344\"\n",
    "GEMINI_2_FLASH = \"gemini-2.0-flash\"\n",
    "\n",
    "\n",
    "# --- Custom Orchestrator Agent ---\n",
    "class StoryFlowAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    Custom agent for a story generation and refinement workflow.\n",
    "\n",
    "    This agent orchestrates a sequence of LLM agents to generate a story,\n",
    "    critique it, revise it, check grammar and tone, and potentially\n",
    "    regenerate the story if the tone is negative.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Field Declarations for Pydantic ---\n",
    "    # Declare the agents passed during initialization as class attributes with type hints\n",
    "    story_generator: LlmAgent\n",
    "    critic: LlmAgent\n",
    "    reviser: LlmAgent\n",
    "    grammar_check: LlmAgent\n",
    "    tone_check: LlmAgent\n",
    "\n",
    "    loop_agent: LoopAgent\n",
    "    sequential_agent: SequentialAgent\n",
    "\n",
    "    # model_config allows setting Pydantic configurations if needed, e.g., arbitrary_types_allowed\n",
    "    model_config = {\"arbitrary_types_allowed\": True}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        story_generator: LlmAgent,\n",
    "        critic: LlmAgent,\n",
    "        reviser: LlmAgent,\n",
    "        grammar_check: LlmAgent,\n",
    "        tone_check: LlmAgent,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the StoryFlowAgent.\n",
    "\n",
    "        Args:\n",
    "            name: The name of the agent.\n",
    "            story_generator: An LlmAgent to generate the initial story.\n",
    "            critic: An LlmAgent to critique the story.\n",
    "            reviser: An LlmAgent to revise the story based on criticism.\n",
    "            grammar_check: An LlmAgent to check the grammar.\n",
    "            tone_check: An LlmAgent to analyze the tone.\n",
    "        \"\"\"\n",
    "        # Create internal agents *before* calling super().__init__\n",
    "        loop_agent = LoopAgent(\n",
    "            name=\"CriticReviserLoop\", sub_agents=[critic, reviser], max_iterations=2\n",
    "        )\n",
    "        sequential_agent = SequentialAgent(\n",
    "            name=\"PostProcessing\", sub_agents=[grammar_check, tone_check]\n",
    "        )\n",
    "\n",
    "        # Define the sub_agents list for the framework\n",
    "        sub_agents_list = [\n",
    "            story_generator,\n",
    "            loop_agent,\n",
    "            sequential_agent,\n",
    "        ]\n",
    "\n",
    "        # Pydantic will validate and assign them based on the class annotations.\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            story_generator=story_generator,\n",
    "            critic=critic,\n",
    "            reviser=reviser,\n",
    "            grammar_check=grammar_check,\n",
    "            tone_check=tone_check,\n",
    "            loop_agent=loop_agent,\n",
    "            sequential_agent=sequential_agent,\n",
    "            sub_agents=sub_agents_list, # Pass the sub_agents list directly\n",
    "        )\n",
    "\n",
    "    @override\n",
    "    async def _run_async_impl(\n",
    "        self, ctx: InvocationContext\n",
    "    ) -> AsyncGenerator[Event, None]:\n",
    "        \"\"\"\n",
    "        Implements the custom orchestration logic for the story workflow.\n",
    "        Uses the instance attributes assigned by Pydantic (e.g., self.story_generator).\n",
    "        \"\"\"\n",
    "        logger.info(f\"[{self.name}] Starting story generation workflow.\")\n",
    "\n",
    "        # print(\"=\" * 100)\n",
    "        # print(\"This is the current context session\")\n",
    "        # print(ctx.session)\n",
    "        # print(\"=\" * 100)\n",
    "\n",
    "        # 1. Initial Story Generation\n",
    "        logger.info(f\"[{self.name}] Running StoryGenerator...\")\n",
    "        async for event in self.story_generator.run_async(ctx):\n",
    "            logger.info(f\"[{self.name}] Event from StoryGenerator: {event.model_dump_json(indent=2, exclude_none=True)}\")\n",
    "            yield event\n",
    "\n",
    "        # Check if story was generated before proceeding\n",
    "        if \"current_story\" not in ctx.session.state or not ctx.session.state[\"current_story\"]:\n",
    "             logger.error(f\"[{self.name}] Failed to generate initial story. Aborting workflow.\")\n",
    "             return # Stop processing if initial story failed\n",
    "\n",
    "        logger.info(f\"[{self.name}] Story state after generator: {ctx.session.state.get('current_story')}\")\n",
    "\n",
    "\n",
    "        # 2. Critic-Reviser Loop\n",
    "        logger.info(f\"[{self.name}] Running CriticReviserLoop...\")\n",
    "        # Use the loop_agent instance attribute assigned during init\n",
    "        async for event in self.loop_agent.run_async(ctx):\n",
    "            logger.info(f\"[{self.name}] Event from CriticReviserLoop: {event.model_dump_json(indent=2, exclude_none=True)}\")\n",
    "            yield event\n",
    "\n",
    "        logger.info(f\"[{self.name}] Story state after loop: {ctx.session.state.get('current_story')}\")\n",
    "\n",
    "        # 3. Sequential Post-Processing (Grammar and Tone Check)\n",
    "        logger.info(f\"[{self.name}] Running PostProcessing...\")\n",
    "        # Use the sequential_agent instance attribute assigned during init\n",
    "        async for event in self.sequential_agent.run_async(ctx):\n",
    "            logger.info(f\"[{self.name}] Event from PostProcessing: {event.model_dump_json(indent=2, exclude_none=True)}\")\n",
    "            yield event\n",
    "\n",
    "        # 4. Tone-Based Conditional Logic\n",
    "        tone_check_result = ctx.session.state.get(\"tone_check_result\")\n",
    "        logger.info(f\"[{self.name}] Tone check result: {tone_check_result}\")\n",
    "\n",
    "        if tone_check_result == \"negative\":\n",
    "            logger.info(f\"[{self.name}] Tone is negative. Regenerating story...\")\n",
    "            async for event in self.story_generator.run_async(ctx):\n",
    "                logger.info(f\"[{self.name}] Event from StoryGenerator (Regen): {event.model_dump_json(indent=2, exclude_none=True)}\")\n",
    "                yield event\n",
    "        else:\n",
    "            logger.info(f\"[{self.name}] Tone is not negative. Keeping current story.\")\n",
    "            pass\n",
    "\n",
    "        logger.info(f\"[{self.name}] Workflow finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the individual LLM agents ---\n",
    "story_generator = LlmAgent(\n",
    "    name=\"StoryGenerator\",\n",
    "    model=GEMINI_2_FLASH,\n",
    "    instruction=\"\"\"You are a story writer. Write a short story (around 100 words) about a cat,\n",
    "based on the topic provided in session state with key 'topic'\"\"\",\n",
    "    input_schema=None,\n",
    "    output_key=\"current_story\",  # Key for storing output in session state\n",
    ")\n",
    "\n",
    "critic = LlmAgent(\n",
    "    name=\"Critic\",\n",
    "    model=GEMINI_2_FLASH,\n",
    "    instruction=\"\"\"You are a story critic. Review the story provided in\n",
    "session state with key 'current_story'. Provide 1-2 sentences of constructive criticism\n",
    "on how to improve it. Focus on plot or character.\"\"\",\n",
    "    input_schema=None,\n",
    "    output_key=\"criticism\",  # Key for storing criticism in session state\n",
    ")\n",
    "\n",
    "reviser = LlmAgent(\n",
    "    name=\"Reviser\",\n",
    "    model=GEMINI_2_FLASH,\n",
    "    instruction=\"\"\"You are a story reviser. Revise the story provided in\n",
    "session state with key 'current_story', based on the criticism in\n",
    "session state with key 'criticism'. Output only the revised story.\"\"\",\n",
    "    input_schema=None,\n",
    "    output_key=\"current_story\",  # Overwrites the original story\n",
    ")\n",
    "\n",
    "grammar_check = LlmAgent(\n",
    "    name=\"GrammarCheck\",\n",
    "    model=GEMINI_2_FLASH,\n",
    "    instruction=\"\"\"You are a grammar checker. Check the grammar of the story\n",
    "provided in session state with key 'current_story'. Output only the suggested\n",
    "corrections as a list, or output 'Grammar is good!' if there are no errors.\"\"\",\n",
    "    input_schema=None,\n",
    "    output_key=\"grammar_suggestions\",\n",
    ")\n",
    "\n",
    "tone_check = LlmAgent(\n",
    "    name=\"ToneCheck\",\n",
    "    model=GEMINI_2_FLASH,\n",
    "    instruction=\"\"\"You are a tone analyzer. Analyze the tone of the story\n",
    "provided in session state with key 'current_story'. Output only one word: 'positive' if\n",
    "the tone is generally positive, 'negative' if the tone is generally negative, or 'neutral'\n",
    "otherwise.\"\"\",\n",
    "    input_schema=None,\n",
    "    output_key=\"tone_check_result\", # This agent's output determines the conditional flow\n",
    ")\n",
    "\n",
    "# --- Create the custom agent instance ---\n",
    "story_flow_agent = StoryFlowAgent(\n",
    "    name=\"StoryFlowAgent\",\n",
    "    story_generator=story_generator,\n",
    "    critic=critic,\n",
    "    reviser=reviser,\n",
    "    grammar_check=grammar_check,\n",
    "    tone_check=tone_check,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 02:43:36.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mInitial session state: {'topic': 'a brave kitten exploring a haunted house'}\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:36.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcall_agent\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mUpdated session state topic to: a lonely robot finding a friend in a junkyard\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:36.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m[StoryFlowAgent] Starting story generation workflow.\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:36.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1m[StoryFlowAgent] Running StoryGenerator...\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:39.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m[StoryFlowAgent] Event from StoryGenerator: {\n",
      "  \"content\": {\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"text\": \"```text\\nUnit 734 hummed, its circuits aching with disuse. Rust blossomed on its chassis in the junkyard sun. It hadn't spoken to another machine in cycles. Then, a flicker of movement. A small, scarred sanitation bot, designated \\\"Whiskers\\\" due to its frayed cleaning brushes, trundled into view.\\n\\nWhiskers beeped a hesitant greeting, its optical sensors dim. Unit 734, surprised, responded with a whirring acknowledgement. Whiskers, unfazed by the larger robot's silence, began tidying around Unit 734's immobile form. A silent companionship bloomed amidst the scrap, the lonely robot finding solace in the tireless efforts of a little cleaning bot.\\n```\\n\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"model\"\n",
      "  },\n",
      "  \"usage_metadata\": {\n",
      "    \"candidates_token_count\": 158,\n",
      "    \"candidates_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 158\n",
      "      }\n",
      "    ],\n",
      "    \"prompt_token_count\": 65,\n",
      "    \"prompt_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 65\n",
      "      }\n",
      "    ],\n",
      "    \"total_token_count\": 223\n",
      "  },\n",
      "  \"invocation_id\": \"e-96cd4e83-9306-49ec-b4e8-d10fdf9fc21c\",\n",
      "  \"author\": \"StoryGenerator\",\n",
      "  \"actions\": {\n",
      "    \"state_delta\": {\n",
      "      \"current_story\": \"```text\\nUnit 734 hummed, its circuits aching with disuse. Rust blossomed on its chassis in the junkyard sun. It hadn't spoken to another machine in cycles. Then, a flicker of movement. A small, scarred sanitation bot, designated \\\"Whiskers\\\" due to its frayed cleaning brushes, trundled into view.\\n\\nWhiskers beeped a hesitant greeting, its optical sensors dim. Unit 734, surprised, responded with a whirring acknowledgement. Whiskers, unfazed by the larger robot's silence, began tidying around Unit 734's immobile form. A silent companionship bloomed amidst the scrap, the lonely robot finding solace in the tireless efforts of a little cleaning bot.\\n```\\n\"\n",
      "    },\n",
      "    \"artifact_delta\": {},\n",
      "    \"requested_auth_configs\": {}\n",
      "  },\n",
      "  \"id\": \"3stxi3xl\",\n",
      "  \"timestamp\": 1750794216.273016\n",
      "}\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:39.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1m[StoryFlowAgent] Story state after generator: ```text\n",
      "Unit 734 hummed, its circuits aching with disuse. Rust blossomed on its chassis in the junkyard sun. It hadn't spoken to another machine in cycles. Then, a flicker of movement. A small, scarred sanitation bot, designated \"Whiskers\" due to its frayed cleaning brushes, trundled into view.\n",
      "\n",
      "Whiskers beeped a hesitant greeting, its optical sensors dim. Unit 734, surprised, responded with a whirring acknowledgement. Whiskers, unfazed by the larger robot's silence, began tidying around Unit 734's immobile form. A silent companionship bloomed amidst the scrap, the lonely robot finding solace in the tireless efforts of a little cleaning bot.\n",
      "```\n",
      "\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:39.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcall_agent\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mPotential final response from [StoryGenerator]: ```text\n",
      "Unit 734 hummed, its circuits aching with disuse. Rust blossomed on its chassis in the junkyard sun. It hadn't spoken to another machine in cycles. Then, a flicker of movement. A small, scarred sanitation bot, designated \"Whiskers\" due to its frayed cleaning brushes, trundled into view.\n",
      "\n",
      "Whiskers beeped a hesitant greeting, its optical sensors dim. Unit 734, surprised, responded with a whirring acknowledgement. Whiskers, unfazed by the larger robot's silence, began tidying around Unit 734's immobile form. A silent companionship bloomed amidst the scrap, the lonely robot finding solace in the tireless efforts of a little cleaning bot.\n",
      "```\n",
      "\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:39.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1m[StoryFlowAgent] Running CriticReviserLoop...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='```text\\nUnit 734 hummed, its circuits aching with disuse. Rust blossomed on its chassis in the junkyard sun. It hadn\\'t spoken to another machine in cycles. Then, a flicker of movement. A small, scarred sanitation bot, designated \"Whiskers\" due to its frayed cleaning brushes, trundled into view.\\n\\nWhiskers beeped a hesitant greeting, its optical sensors dim. Unit 734, surprised, responded with a whirring acknowledgement. Whiskers, unfazed by the larger robot\\'s silence, began tidying around Unit 734\\'s immobile form. A silent companionship bloomed amidst the scrap, the lonely robot finding solace in the tireless efforts of a little cleaning bot.\\n```\\n')], role='model') grounding_metadata=None partial=None turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=158, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=158)], prompt_token_count=65, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=65)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=223, traffic_type=None) invocation_id='e-96cd4e83-9306-49ec-b4e8-d10fdf9fc21c' author='StoryGenerator' actions=EventActions(skip_summarization=None, state_delta={'current_story': '```text\\nUnit 734 hummed, its circuits aching with disuse. Rust blossomed on its chassis in the junkyard sun. It hadn\\'t spoken to another machine in cycles. Then, a flicker of movement. A small, scarred sanitation bot, designated \"Whiskers\" due to its frayed cleaning brushes, trundled into view.\\n\\nWhiskers beeped a hesitant greeting, its optical sensors dim. Unit 734, surprised, responded with a whirring acknowledgement. Whiskers, unfazed by the larger robot\\'s silence, began tidying around Unit 734\\'s immobile form. A silent companionship bloomed amidst the scrap, the lonely robot finding solace in the tireless efforts of a little cleaning bot.\\n```\\n'}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='3stxi3xl' timestamp=1750794216.273016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 02:43:41.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1m[StoryFlowAgent] Event from CriticReviserLoop: {\n",
      "  \"content\": {\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"text\": \"The story is sweet and simple, but could benefit from a more active role for Unit 734; perhaps it could use its greater size or strength to help Whiskers with a difficult task, solidifying their friendship through action rather than just passive acceptance.\\n\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"model\"\n",
      "  },\n",
      "  \"usage_metadata\": {\n",
      "    \"candidates_token_count\": 53,\n",
      "    \"candidates_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 53\n",
      "      }\n",
      "    ],\n",
      "    \"prompt_token_count\": 238,\n",
      "    \"prompt_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 238\n",
      "      }\n",
      "    ],\n",
      "    \"total_token_count\": 291\n",
      "  },\n",
      "  \"invocation_id\": \"e-96cd4e83-9306-49ec-b4e8-d10fdf9fc21c\",\n",
      "  \"author\": \"Critic\",\n",
      "  \"actions\": {\n",
      "    \"state_delta\": {\n",
      "      \"criticism\": \"The story is sweet and simple, but could benefit from a more active role for Unit 734; perhaps it could use its greater size or strength to help Whiskers with a difficult task, solidifying their friendship through action rather than just passive acceptance.\\n\"\n",
      "    },\n",
      "    \"artifact_delta\": {},\n",
      "    \"requested_auth_configs\": {}\n",
      "  },\n",
      "  \"id\": \"ddrKbm67\",\n",
      "  \"timestamp\": 1750794219.753899\n",
      "}\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:41.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcall_agent\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mPotential final response from [Critic]: The story is sweet and simple, but could benefit from a more active role for Unit 734; perhaps it could use its greater size or strength to help Whiskers with a difficult task, solidifying their friendship through action rather than just passive acceptance.\n",
      "\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:45.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1m[StoryFlowAgent] Event from CriticReviserLoop: {\n",
      "  \"content\": {\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"text\": \"Unit 734 hummed, its circuits aching with disuse. Rust blossomed on its chassis in the junkyard sun. It hadn't spoken to another machine in cycles. Then, a flicker of movement. A small, scarred sanitation bot, designated \\\"Whiskers\\\" due to its frayed cleaning brushes, trundled into view.\\n\\nWhiskers beeped a hesitant greeting, its optical sensors dim. Unit 734, surprised, responded with a whirring acknowledgement. Whiskers, unfazed by the larger robot's silence, began tidying around a particularly large pile of debris. Unit 734 watched as Whiskers strained, its small treads slipping on the uneven ground. With a groan of protesting gears, Unit 734 extended a massive arm, gently scooping up the pile and depositing it into a nearby crusher. Whiskers beeped excitedly, whirling in a circle. From then on, a silent partnership bloomed amidst the scrap, the lonely robot finding solace and purpose in aiding the tireless little cleaning bot.\\n\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"model\"\n",
      "  },\n",
      "  \"usage_metadata\": {\n",
      "    \"candidates_token_count\": 216,\n",
      "    \"candidates_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 216\n",
      "      }\n",
      "    ],\n",
      "    \"prompt_token_count\": 300,\n",
      "    \"prompt_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 300\n",
      "      }\n",
      "    ],\n",
      "    \"total_token_count\": 516\n",
      "  },\n",
      "  \"invocation_id\": \"e-96cd4e83-9306-49ec-b4e8-d10fdf9fc21c\",\n",
      "  \"author\": \"Reviser\",\n",
      "  \"actions\": {\n",
      "    \"state_delta\": {\n",
      "      \"current_story\": \"Unit 734 hummed, its circuits aching with disuse. Rust blossomed on its chassis in the junkyard sun. It hadn't spoken to another machine in cycles. Then, a flicker of movement. A small, scarred sanitation bot, designated \\\"Whiskers\\\" due to its frayed cleaning brushes, trundled into view.\\n\\nWhiskers beeped a hesitant greeting, its optical sensors dim. Unit 734, surprised, responded with a whirring acknowledgement. Whiskers, unfazed by the larger robot's silence, began tidying around a particularly large pile of debris. Unit 734 watched as Whiskers strained, its small treads slipping on the uneven ground. With a groan of protesting gears, Unit 734 extended a massive arm, gently scooping up the pile and depositing it into a nearby crusher. Whiskers beeped excitedly, whirling in a circle. From then on, a silent partnership bloomed amidst the scrap, the lonely robot finding solace and purpose in aiding the tireless little cleaning bot.\\n\"\n",
      "    },\n",
      "    \"artifact_delta\": {},\n",
      "    \"requested_auth_configs\": {}\n",
      "  },\n",
      "  \"id\": \"kuKD6MxB\",\n",
      "  \"timestamp\": 1750794221.863573\n",
      "}\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:45.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcall_agent\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mPotential final response from [Reviser]: Unit 734 hummed, its circuits aching with disuse. Rust blossomed on its chassis in the junkyard sun. It hadn't spoken to another machine in cycles. Then, a flicker of movement. A small, scarred sanitation bot, designated \"Whiskers\" due to its frayed cleaning brushes, trundled into view.\n",
      "\n",
      "Whiskers beeped a hesitant greeting, its optical sensors dim. Unit 734, surprised, responded with a whirring acknowledgement. Whiskers, unfazed by the larger robot's silence, began tidying around a particularly large pile of debris. Unit 734 watched as Whiskers strained, its small treads slipping on the uneven ground. With a groan of protesting gears, Unit 734 extended a massive arm, gently scooping up the pile and depositing it into a nearby crusher. Whiskers beeped excitedly, whirling in a circle. From then on, a silent partnership bloomed amidst the scrap, the lonely robot finding solace and purpose in aiding the tireless little cleaning bot.\n",
      "\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:47.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1m[StoryFlowAgent] Event from CriticReviserLoop: {\n",
      "  \"content\": {\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"text\": \"The revision adds a nice element of active participation from Unit 734, making their connection feel more earned and less one-sided.\\n\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"model\"\n",
      "  },\n",
      "  \"usage_metadata\": {\n",
      "    \"candidates_token_count\": 29,\n",
      "    \"candidates_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 29\n",
      "      }\n",
      "    ],\n",
      "    \"prompt_token_count\": 516,\n",
      "    \"prompt_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 516\n",
      "      }\n",
      "    ],\n",
      "    \"total_token_count\": 545\n",
      "  },\n",
      "  \"invocation_id\": \"e-96cd4e83-9306-49ec-b4e8-d10fdf9fc21c\",\n",
      "  \"author\": \"Critic\",\n",
      "  \"actions\": {\n",
      "    \"state_delta\": {\n",
      "      \"criticism\": \"The revision adds a nice element of active participation from Unit 734, making their connection feel more earned and less one-sided.\\n\"\n",
      "    },\n",
      "    \"artifact_delta\": {},\n",
      "    \"requested_auth_configs\": {}\n",
      "  },\n",
      "  \"id\": \"duoS6v3t\",\n",
      "  \"timestamp\": 1750794225.064524\n",
      "}\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:47.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcall_agent\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mPotential final response from [Critic]: The revision adds a nice element of active participation from Unit 734, making their connection feel more earned and less one-sided.\n",
      "\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:48.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1m[StoryFlowAgent] Event from CriticReviserLoop: {\n",
      "  \"content\": {\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"text\": \"Okay, I understand. There are no further revisions requested.\\n\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"model\"\n",
      "  },\n",
      "  \"usage_metadata\": {\n",
      "    \"candidates_token_count\": 13,\n",
      "    \"candidates_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 13\n",
      "      }\n",
      "    ],\n",
      "    \"prompt_token_count\": 553,\n",
      "    \"prompt_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 553\n",
      "      }\n",
      "    ],\n",
      "    \"total_token_count\": 566\n",
      "  },\n",
      "  \"invocation_id\": \"e-96cd4e83-9306-49ec-b4e8-d10fdf9fc21c\",\n",
      "  \"author\": \"Reviser\",\n",
      "  \"actions\": {\n",
      "    \"state_delta\": {\n",
      "      \"current_story\": \"Okay, I understand. There are no further revisions requested.\\n\"\n",
      "    },\n",
      "    \"artifact_delta\": {},\n",
      "    \"requested_auth_configs\": {}\n",
      "  },\n",
      "  \"id\": \"qK2zWO2q\",\n",
      "  \"timestamp\": 1750794227.302571\n",
      "}\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:48.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1m[StoryFlowAgent] Story state after loop: Okay, I understand. There are no further revisions requested.\n",
      "\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:48.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcall_agent\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mPotential final response from [Reviser]: Okay, I understand. There are no further revisions requested.\n",
      "\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:48.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1m[StoryFlowAgent] Running PostProcessing...\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:49.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m[StoryFlowAgent] Event from PostProcessing: {\n",
      "  \"content\": {\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"text\": \"Grammar is good!\\n\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"model\"\n",
      "  },\n",
      "  \"usage_metadata\": {\n",
      "    \"candidates_token_count\": 5,\n",
      "    \"candidates_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 5\n",
      "      }\n",
      "    ],\n",
      "    \"prompt_token_count\": 589,\n",
      "    \"prompt_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 589\n",
      "      }\n",
      "    ],\n",
      "    \"total_token_count\": 594\n",
      "  },\n",
      "  \"invocation_id\": \"e-96cd4e83-9306-49ec-b4e8-d10fdf9fc21c\",\n",
      "  \"author\": \"GrammarCheck\",\n",
      "  \"actions\": {\n",
      "    \"state_delta\": {\n",
      "      \"grammar_suggestions\": \"Grammar is good!\\n\"\n",
      "    },\n",
      "    \"artifact_delta\": {},\n",
      "    \"requested_auth_configs\": {}\n",
      "  },\n",
      "  \"id\": \"vqP1eWfI\",\n",
      "  \"timestamp\": 1750794228.216014\n",
      "}\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:49.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcall_agent\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mPotential final response from [GrammarCheck]: Grammar is good!\n",
      "\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:51.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1m[StoryFlowAgent] Event from PostProcessing: {\n",
      "  \"content\": {\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"text\": \"positive\\n\"\n",
      "      }\n",
      "    ],\n",
      "    \"role\": \"model\"\n",
      "  },\n",
      "  \"usage_metadata\": {\n",
      "    \"candidates_token_count\": 2,\n",
      "    \"candidates_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 2\n",
      "      }\n",
      "    ],\n",
      "    \"prompt_token_count\": 612,\n",
      "    \"prompt_tokens_details\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"token_count\": 612\n",
      "      }\n",
      "    ],\n",
      "    \"total_token_count\": 614\n",
      "  },\n",
      "  \"invocation_id\": \"e-96cd4e83-9306-49ec-b4e8-d10fdf9fc21c\",\n",
      "  \"author\": \"ToneCheck\",\n",
      "  \"actions\": {\n",
      "    \"state_delta\": {\n",
      "      \"tone_check_result\": \"positive\\n\"\n",
      "    },\n",
      "    \"artifact_delta\": {},\n",
      "    \"requested_auth_configs\": {}\n",
      "  },\n",
      "  \"id\": \"v3yKV9Ri\",\n",
      "  \"timestamp\": 1750794229.935708\n",
      "}\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:51.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1m[StoryFlowAgent] Tone check result: positive\n",
      "\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:51.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcall_agent\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mPotential final response from [ToneCheck]: positive\n",
      "\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:51.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1m[StoryFlowAgent] Tone is not negative. Keeping current story.\u001b[0m\n",
      "\u001b[32m2025-06-25 02:43:51.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_async_impl\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1m[StoryFlowAgent] Workflow finished.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Agent Interaction Result ---\n",
      "Agent Final Response:  positive\n",
      "\n",
      "Final Session State:\n",
      "{\n",
      "  \"topic\": \"a brave kitten exploring a haunted house\",\n",
      "  \"current_story\": \"Okay, I understand. There are no further revisions requested.\\n\",\n",
      "  \"criticism\": \"The revision adds a nice element of active participation from Unit 734, making their connection feel more earned and less one-sided.\\n\",\n",
      "  \"grammar_suggestions\": \"Grammar is good!\\n\",\n",
      "  \"tone_check_result\": \"positive\\n\"\n",
      "}\n",
      "-------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Setup Runner and Session ---\n",
    "session_service = InMemorySessionService()\n",
    "initial_state = {\"topic\": \"a brave kitten exploring a haunted house\"}\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    "    state=initial_state # Pass initial state here\n",
    ")\n",
    "logger.info(f\"Initial session state: {session.state}\")\n",
    "\n",
    "runner = Runner(\n",
    "    agent=story_flow_agent, # Pass the custom orchestrator agent\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "# --- Function to Interact with the Agent ---\n",
    "async def call_agent(user_input_topic: str):\n",
    "    \"\"\"\n",
    "    Sends a new topic to the agent (overwriting the initial one if needed)\n",
    "    and runs the workflow.\n",
    "    \"\"\"\n",
    "    current_session = await session_service.get_session(app_name=APP_NAME, \n",
    "                                                  user_id=USER_ID, \n",
    "                                                  session_id=SESSION_ID)\n",
    "    if not current_session:\n",
    "        logger.error(\"Session not found!\")\n",
    "        return\n",
    "\n",
    "    current_session.state[\"topic\"] = user_input_topic\n",
    "    logger.info(f\"Updated session state topic to: {user_input_topic}\")\n",
    "\n",
    "    content = types.Content(role='user', parts=[types.Part(text=f\"Generate a story about: {user_input_topic}\")])\n",
    "    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)\n",
    "\n",
    "    final_response = \"No final response captured.\"\n",
    "    for event in events:\n",
    "        if event.is_final_response() and event.content and event.content.parts:\n",
    "            logger.info(f\"Potential final response from [{event.author}]: {event.content.parts[0].text}\")\n",
    "            final_response = event.content.parts[0].text\n",
    "\n",
    "    print(\"\\n--- Agent Interaction Result ---\")\n",
    "    print(\"Agent Final Response: \", final_response)\n",
    "\n",
    "    final_session = await session_service.get_session(app_name=APP_NAME, \n",
    "                                                user_id=USER_ID, \n",
    "                                                session_id=SESSION_ID)\n",
    "    print(\"Final Session State:\")\n",
    "    import json\n",
    "    print(json.dumps(final_session.state, indent=2))\n",
    "    print(\"-------------------------------\\n\")\n",
    "\n",
    "# --- Run the Agent ---\n",
    "await call_agent(\"a lonely robot finding a friend in a junkyard\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
